{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Raiyan Abdul Baten\n",
    "\n",
    "University of Rochester, NY, USA\n",
    "\n",
    "Mail: raiyanabdulbaten@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression \n",
    "## Implementation and Cheat Sheet\n",
    "\n",
    "This page documents the summary theory and implementation of ridge regression. In particular, it covers:\n",
    "\n",
    "- Ridge regression\n",
    "- k-fold cross validation to find best l2-penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from IPython.display import display, Math, Latex\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_csv_data(folder_name, file_name, dtype_dict=None):\n",
    "    csv_path = os.path.join(folder_name, file_name+\".csv\")\n",
    "    return pd.read_csv(csv_path, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, \\\n",
    "              'sqft_living15':float, 'grade':int, 'yr_renovated':int, \\\n",
    "              'price':float, 'bedrooms':float, 'zipcode':str, \\\n",
    "              'long':float, 'sqft_lot15':float, 'sqft_living':float, \\\n",
    "              'floors':str, 'condition':int, 'lat':float, 'date':str, \\\n",
    "              'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ridge = load_csv_data(\"data\",\"kc_house_train_data\",dtype_dict)\n",
    "df_test_ridge = load_csv_data(\"data\",\"kc_house_test_data\",dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "Regression model:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{y}=\\mathbf{X}\\mathbf{w}+\\mathbf{\\epsilon},\n",
    "\\end{equation}\n",
    "where $\\mathbf{y}\\in \\mathbb{R}^{N\\times 1}, \\mathbf{X}\\in \\mathbb{R}^{N\\times p}, \\mathbf{w}\\in \\mathbb{R}^{p\\times 1},\\mathbf{\\epsilon}\\in \\mathbb{R}^{N\\times 1}$\n",
    "\n",
    "Total cost = measure of fit + measure of magnitude of coefficients = $\\text{RSS}(\\mathbf{w}) + \\lambda||\\mathbf{w}||_2^2$\n",
    "\n",
    "where $||\\mathbf{w}||_2^2 = w_0^2+w_1^2+...+w_{p-1}^2$. Here, $w_0$ is the intercept, and there are $p-1$ actual features, giving a total of $p$ features.\n",
    "\n",
    "Here,\n",
    "\\begin{equation}\n",
    " \\text{RSS}(\\mathbf{w}) = (\\mathbf{y}-\\mathbf{\\hat{y}})^\\text{T}(\\mathbf{y}-\\mathbf{\\hat{y}}) = (\\mathbf{y}-\\mathbf{X}\\mathbf{w})^\\text{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{w})\n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation}\n",
    " ||\\mathbf{w}||_2^2 = \\mathbf{w}^{\\text{T}}\\mathbf{w}\n",
    "\\end{equation}\n",
    "\n",
    "Therefore,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Total cost} = (\\mathbf{y}-\\mathbf{X}\\mathbf{w})^\\text{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{w}) + \\lambda \\mathbf{w}^{\\text{T}}\\mathbf{w}\n",
    "\\end{equation}\n",
    "\n",
    "Taking the gradient of the cost,\n",
    "\\begin{equation}\n",
    " \\nabla (\\text{RSS}(\\mathbf{w}) + \\lambda||\\mathbf{w}||_2^2) = \\nabla ((\\mathbf{y}-\\mathbf{X}\\mathbf{w})^\\text{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{w}) + \\lambda \\mathbf{w}^{\\text{T}}\\mathbf{w}) \n",
    " \\end{equation}\n",
    " \\begin{equation}\n",
    " = -2\\mathbf{X}^\\text{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{w}) + \\lambda (2 \\mathbf{w}) = -2\\mathbf{X}^\\text{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{w}) + 2\\lambda \\mathbb{I}\\mathbf{w}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The closed form solution can be found by setting the gradient to 0:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    " \\nabla (\\text{cost}(\\mathbf{\\hat{w}})) = \\nabla (-2\\mathbf{X}^\\text{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{\\hat{w}}) + 2\\lambda \\mathbb{I}\\mathbf{\\hat{w}}) = 0 \n",
    "  \\end{equation}\n",
    " \\begin{equation}\n",
    " \\mathbf{\\hat{w}}^{\\text{ridge}} = (\\mathbf{X}^{\\text{T}}\\mathbf{X}+\\lambda \\mathbb{I})^{-1} \\mathbf{X}^{\\text{T}}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "However, we do not want to penalize the intercept $w_0$ for being large. Therefore, use a modified $\\mathbb{I}^{\\text{mod}} = \\begin{bmatrix}0 &  & & &\\\\  & 1 &  & & \\\\ &  & 1 &  &\\\\  &  &  & \\ddots & \\\\&  & & & 1 \\end{bmatrix}$, with $\\mathbb{I}\\in\\mathbb{R}^{p\\times p}$\n",
    "\n",
    "\n",
    "Using Gradient Descent:\n",
    "\n",
    "init $t=1, \\mathbf{w}^{(1)}=0$ or randomly or smartly\n",
    "\n",
    "while $||\\nabla \\text{RSS}(\\mathbf{w}^{(t)})||>$threshold:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w}^{(t+1)} <= \\mathbf{w}^{(t)} +2\\eta(\\mathbf{X}^\\text{T}(\\mathbf{y}-\\mathbf{X}\\mathbf{w}^{(t)})-\\lambda\\mathbb{I}^{\\text{mod}}\\mathbf{w})\\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_gradient_descent(feature_matrix, target, initial_weights,\\\n",
    "                                      step_size, l2_penalty, max_iterations=100):\n",
    "    \n",
    "    weights = np.array(initial_weights)\n",
    "    I = np.identity(weights.size)\n",
    "    I[0][0]=0\n",
    "    for iteration in range(max_iterations):\n",
    "        gradient_RSS = -2*np.matmul(np.transpose(feature_matrix),target-np.matmul(feature_matrix,weights))\n",
    "        gradient_regularization = 2*l2_penalty*np.matmul(I,weights)\n",
    "        total_cost=gradient_RSS+gradient_regularization\n",
    "        weights = weights - step_size*total_cost\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_closed_form(feature_matrix,target,l2_penalty):\n",
    "    I = np.identity(feature_matrix.shape[1])\n",
    "    I[0][0]=0\n",
    "    weights = np.matmul(np.linalg.inv(np.matmul(np.transpose(feature_matrix),feature_matrix)+l2_penalty*I),\\\n",
    "                        np.matmul(np.transpose(feature_matrix),target))\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_prepare(dataframe,features,target):\n",
    "    dataframe[\"constant\"]=1\n",
    "    one_padded_features=[\"constant\"]\n",
    "    one_padded_features.extend(features)\n",
    "    X = dataframe[one_padded_features].values\n",
    "    Y = dataframe[target].values\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcome(feature_matrix, weights):\n",
    "    predictions = np.matmul(feature_matrix,weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The small-penalty weights from ridge gradient descent are: \n",
      "[[-9.99999771e+04]\n",
      " [ 2.45183819e+02]\n",
      " [ 6.51587638e+01]]\n",
      "The small-penalty weights from ridge closed form solution are: \n",
      "[[-1.00262175e+05]\n",
      " [ 2.45188714e+02]\n",
      " [ 6.52715852e+01]]\n"
     ]
    }
   ],
   "source": [
    "simple_features = ['sqft_living', 'sqft_living15']\n",
    "X_train,Y_train=dataframe_prepare(df_train_ridge,simple_features,['price'])\n",
    "X_test,Y_test=dataframe_prepare(df_test_ridge,simple_features,['price'])\n",
    "initial_weights = np.array([[-100000.], [0.], [0.]])\n",
    "step_size = 1e-12\n",
    "max_iterations= 10000\n",
    "\n",
    "multiple_weights_small_penalty = ridge_regression_gradient_descent(X_train, Y_train, initial_weights=initial_weights,\\\n",
    "                                            step_size=step_size, l2_penalty=1.5e-5, max_iterations=max_iterations)\n",
    "print(\"The small-penalty weights from ridge gradient descent are: \")\n",
    "print(multiple_weights_small_penalty)\n",
    "\n",
    "weights_closed = ridge_regression_closed_form(X_train, Y_train,l2_penalty=1.5e-5)\n",
    "print(\"The small-penalty weights from ridge closed form solution are: \")\n",
    "print(weights_closed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.5e-05, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=True, random_state=None, solver='auto', tol=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_small_penalty = 1.5e-5\n",
    "model = linear_model.Ridge(alpha=l2_small_penalty,max_iter=10000,tol=None, normalize=True)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100259.76546574])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        , 245.18141126,  65.27802084]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore 0-penalty and infinity-penalty effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0-penalty weights from ridge gradient descent are: \n",
      "[[-9.99999771e+04]\n",
      " [ 2.45183819e+02]\n",
      " [ 6.51587638e+01]]\n",
      "The 0-penalty weights from ridge closed form solution are: \n",
      "[[-1.00262175e+05]\n",
      " [ 2.45188714e+02]\n",
      " [ 6.52715852e+01]]\n",
      "The high-penalty weights from ridge gradient descent are: \n",
      "[[-9.99169711e+04]\n",
      " [ 1.04826258e+02]\n",
      " [ 9.19077002e+01]]\n",
      "The high-penalty weights from ridge closed form solution are: \n",
      "[[4.25149484e+05]\n",
      " [3.47447641e+01]\n",
      " [2.11214072e+01]]\n"
     ]
    }
   ],
   "source": [
    "multiple_weights_0_penalty = ridge_regression_gradient_descent(X_train, Y_train, initial_weights=initial_weights,\\\n",
    "                                            step_size=step_size, l2_penalty=0, max_iterations=max_iterations)\n",
    "print(\"The 0-penalty weights from ridge gradient descent are: \")\n",
    "print(multiple_weights_0_penalty)\n",
    "\n",
    "weights_closed = ridge_regression_closed_form(X_train, Y_train,l2_penalty=0)\n",
    "print(\"The 0-penalty weights from ridge closed form solution are: \")\n",
    "print(weights_closed)\n",
    "\n",
    "multiple_weights_high_penalty = ridge_regression_gradient_descent(X_train, Y_train, initial_weights=initial_weights,\\\n",
    "                                            step_size=step_size, l2_penalty=1e11, max_iterations=max_iterations)\n",
    "print(\"The high-penalty weights from ridge gradient descent are: \")\n",
    "print(multiple_weights_high_penalty)\n",
    "\n",
    "weights_closed = ridge_regression_closed_form(X_train, Y_train,l2_penalty=1e11)\n",
    "print(\"The high-penalty weights from ridge closed form solution are: \")\n",
    "print(weights_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10b3d6898>,\n",
       " <matplotlib.lines.Line2D at 0x10b3d6b38>,\n",
       " <matplotlib.lines.Line2D at 0x10b3d6f98>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztvXuUXFWd6P/5VlVXB1BI0kQCCRhU\n0Ik3TgJ9m67rGEqjEaJLei6zZlDu7QwQQiuoUX/TJOPlygx3JdKgRAShm9ekZ1CGMSOPkchAJiWZ\n6QohMQgYXgF5JEMgBBEHSD+qvr8/zj7Vp6qrqqs6Vd1Vne9nrb3qnH32OXufU93nW9/H/m5RVQzD\nMAyjmoQmegCGYRjG5MeEjWEYhlF1TNgYhmEYVceEjWEYhlF1TNgYhmEYVceEjWEYhlF1TNgYhmEY\nVceEjWEYhlF1ShI2IvINEfmNiDwhIj8RkSkicqKIPCwiu0TkH0Uk6to2uv1d7vicwHVWufqnReSz\ngfozXN0uEVkZqC+7D8MwDKP2kNEyCIjILODfgbmq+q6I3AncBywB/llV7xCRG4Ffq+oNIvIV4GOq\n2iEi5wB/qqp/ISJzgZ8ALcBxwIPAya6bZ4DPALuBR4AvqupO11fJfRS7j6OPPlrnzJlT/hMyDMM4\nhNm+ffvrqjrjYK8TKaPdYSIyCBwOvAJ8CviSO74OuBy4ATjLbQP8FLhORMTV36Gq/cBvRWQXnuAB\n2KWqzwOIyB3AWSLyZLl9aBHJOWfOHLZt21bi7RqGYRgAIvJiJa4zqhlNVfcAVwMv4QmZ3wPbgTdV\ndcg12w3MctuzgJfduUOufVOwPuecQvVNY+jDMAzDqEFGFTYiMg1PkzgRz/x1BHBGlcdVEURkuYhs\nE5Ft+/btm+jhGIZhHLKUEiDwaeC3qrpPVQeBfwY+DkwVEd8MNxvY47b3AMcDuONHAfuD9TnnFKrf\nP4Y+slDVHlVtVtXmGTMO2uRoGIZhjJFShM1LQKuIHO58L4uAncAm4M9cm6XA3W77HrePO/5vzpdy\nD3COiyQ7ETgJ2IoXEHCSizyLAucA97hzyu3DMAzDqEFGDRBQ1YdF5KfAr4AhYAfQA/wcuENE/p+r\nu8Wdcgvw9y4A4A084YGq/sZFl+1017lYVVMAInIJcD8QBm5V1d+4a11aTh+GYRhGbTJq6PNkobm5\nWS0azTAMozxEZLuqNh/sdSyDgGEYRoVJJpOsWbOGZDI50UOpGUqdZ2MYhmGUQDKZZNGiRQwMDBCN\nRtm4cSOxWGyihzXhmGZjGIZRQRKJBAMDA6RSKQYGBkgkEhM9pJrAhI1hGEYFicfjRKNRwuEw0WiU\neDw+0UOqCcyMZhiGUUFisRgbN24kkUgQj8fNhOYwYWMYhlFhYrGYCZkczIxmGIZhVB0TNoZhGEbV\nMWFjGIZhVB0TNoZhGEbVMWFjGIZhVB0TNoZhGEbVMWFjGIZhVB0TNoZhGEbVMWFjGIZhVB0TNoZh\nGEbVMWFjGIZhVJ1RhY2IfFhEHg2Ut0RkhYhMF5EHRORZ9znNtRcRuVZEdonIYyJySuBaS137Z0Vk\naaD+VBF53J1zrYiIqy+7D8MwJg+2CNnkYVRho6pPq+p8VZ0PnAq8A/wMWAlsVNWTgI1uH+BM4CRX\nlgM3gCc4gO8ApwEtwHd84eHaXBg47wxXX1YfhmFMHvxFyC677DIWLVpkAqfOKdeMtgh4TlVfBM4C\n1rn6dUCb2z4L6FWPLcBUETkW+CzwgKq+oaq/Ax4AznDHjlTVLaqqQG/OtcrpwzCMSYItQja5KFfY\nnAP8xG0fo6qvuO29wDFuexbwcuCc3a6uWP3uPPVj6SMLEVkuIttEZNu+fftKukHDMGoDW4RsclHy\nejYiEgW+AKzKPaaqKiJayYFVog9V7QF6AJqbm6s6PsMwKostQja5KGfxtDOBX6nqq27/VRE5VlVf\ncSas11z9HuD4wHmzXd0eIJ5Tn3D1s/O0H0sfhmFMImwRsslDOWa0LzJsQgO4B/AjypYCdwfq213E\nWCvwe2cKux9YLCLTXGDAYuB+d+wtEWl1UWjtOdcqpw/DMAyjBilJsxGRI4DPABcFqr8L3CkiFwAv\nAn/u6u8DlgC78CLXzgNQ1TdE5ArgEdfub1X1Dbf9FeDvgMOADa6U3YdhGIZRm4gXADb5aW5u1m3b\ntk30MAzDMOoKEdmuqs0Hex3LIGAYhmFUHRM2hmEYRtUxYWMYhmFUHRM2hmEYRtUxYWMYhmFUHRM2\nhmEYRtUxYWMYhmFUHRM2hmEYRtUxYWMYhmFUHRM2hmEYRtUxYWMYhmFUHRM2hmEYRtUxYWMYhmFU\nHRM2hmEYRtUxYWMYhmFUHRM2hmEYRtUpSdiIyFQR+amIPCUiT4pITESmi8gDIvKs+5zm2oqIXCsi\nu0TkMRE5JXCdpa79syKyNFB/qog87s651i0PzVj6MAzDMGqPUjWbHwC/UNWPAH8MPAmsBDaq6knA\nRrcPcCZwkivLgRvAExzAd4DTgBbgO77wcG0uDJx3hqsvqw/DMAyjNhlV2IjIUcBC4BYAVR1Q1TeB\ns4B1rtk6oM1tnwX0qscWYKqIHAt8FnhAVd9Q1d8BDwBnuGNHquoW9dao7s25Vjl9GIZhGDVIKZrN\nicA+4DYR2SEiN4vIEcAxqvqKa7MXOMZtzwJeDpy/29UVq9+dp54x9GEYhmHUIKUImwhwCnCDqi4A\n3mbYnAWA00i08sM7uD5EZLmIbBORbfv27avSyAzDMIzRKEXY7AZ2q+rDbv+neMLnVd905T5fc8f3\nAMcHzp/t6orVz85Tzxj6yEJVe1S1WVWbZ8yYUcKtGoZhGNVgVGGjqnuBl0Xkw65qEbATuAfwI8qW\nAne77XuAdhcx1gr83pnC7gcWi8g0FxiwGLjfHXtLRFpdFFp7zrXK6cMwDMOoQSIltvsqcLuIRIHn\ngfPwBNWdInIB8CLw567tfcASYBfwjmuLqr4hIlcAj7h2f6uqb7jtrwB/BxwGbHAF4Lvl9GEYhmHU\nJuK5QiY/zc3Num3btokehmEYRl0hIttVtflgr2MZBAzDMIyqY8LGMAzDqDombAzDMIyqY8LGMAzD\nqDombAzDqCjJZJI1a9aQTCYneihGDVFq6LNhGMaoJJNJFi1axMDAANFolI0bNxKLxSZ6WEYNYJqN\nYRgVI5FIMDAwQCqVYmBggEQiMdFDMmoEEzaGYVSMeDxONBolHA4TjUaJx+MTPSSjRjAzmmEYFSMW\ni7Fx40YSiQTxeNxMaEYGEzaGYVSUWCxmQsYYgZnRDGOSY9FhRi1gmo1h1AnJZLJs85RFhxm1ggkb\nw6gDxio08kWHmbAxJgIzoxlGHTDWkGKLDjNqBdNsDKMO8IWGr9mUKjQsOsyoFWw9G8OoE8biszGM\ng6VS69mYZmMYdcLBhBSboDImmpJ8NiLygog8LiKPisg2VzddRB4QkWfd5zRXLyJyrYjsEpHHROSU\nwHWWuvbPisjSQP2p7vq73Lky1j4Mw8jGDy647LLLWLRokYVAGxNCOQECn1TV+QF1aiWwUVVPAja6\nfYAzgZNcWQ7cAJ7gAL4DnAa0AN/xhYdrc2HgvDPG0odhGCOxfGVGLXAw0WhnAevc9jqgLVDfqx5b\ngKkicizwWeABVX1DVX8HPACc4Y4dqapb1HMg9eZcq5w+DMPIwSLSjFqgVJ+NAv8qIgp0q2oPcIyq\nvuKO7wWOcduzgJcD5+52dcXqd+epZwx9vIJhGFlYRJpRC5QqbP5EVfeIyPuAB0TkqeBBVVUniKrG\nWPoQkeV4ZjZOOOGEqozLMOoBy1dmTDQlmdFUdY/7fA34GZ7P5VXfdOU+X3PN9wDHB06f7eqK1c/O\nU88Y+sgdd4+qNqtq84wZM0q5VcMwDKMKjCpsROQIEXmvvw0sBp4A7gH8iLKlwN1u+x6g3UWMtQK/\nd6aw+4HFIjLNBQYsBu53x94SkVYXhdaec61y+jAMwzBqkFLMaMcAP3PRyBHgx6r6CxF5BLhTRC4A\nXgT+3LW/D1gC7ALeAc4DUNU3ROQK4BHX7m9V9Q23/RXg74DDgA2uAHy3nD4MwzCM2sQyCBiGYRgF\nqVQGAUvEaRiGYVQdEzaGYUwItqjboYXlRjMMY9yxRd0OPUyzMQxj3LEUOoceJmwMwxh3LIXOoYeZ\n0QzDGHcshc6hhwkbw6gw+daOsfVkRmIpdA4tTNgYRgXJ5/gGzBluHPKYsDGMClLI8Z1bZ8LGONQw\nYWMYFcR3fPtajO/4zldnGIcSJmwMo4IUcnybM9w41LHcaIZhGEZBLDeaYRiGUTeYsDGMOsNyihn1\niPlsDKOOsJxiRr1imo1h1BGWU8yoV0zYGEYdYTnFjHqlZGEjImER2SEi/+L2TxSRh0Vkl4j8o4hE\nXX2j29/ljs8JXGOVq39aRD4bqD/D1e0SkZWB+rL7MIzJjB9afcUVV5gJzagrytFsvg48Gdi/ErhG\nVT8E/A64wNVfAPzO1V/j2iEic4FzgI8CZwA/cgIsDFwPnAnMBb7o2pbdh2EcCsRiMVatWmWCxqgr\nShI2IjIb+Bxws9sX4FPAT12TdUCb2z7L7eOOL3LtzwLuUNV+Vf0tsAtocWWXqj6vqgPAHcBZY+zD\nMOoaizQzJiulRqOtBTqB97r9JuBNVR1y+7uBWW57FvAygKoOicjvXftZwJbANYPnvJxTf9oY+3i9\nxPsxjJrDIs2Mycyomo2IfB54TVW3j8N4KoqILBeRbSKybd++fRM9HMMoikWaGZOZUsxoHwe+ICIv\n4Jm4PgX8AJgqIr5mNBvY47b3AMcDuONHAfuD9TnnFKrfP4Y+slDVHlVtVtXmGTNmlHCrhuExEeYs\nizQzJjOjmtFUdRWwCkBE4sD/p6rnisg/AX+GJ4CWAne7U+5x+0l3/N9UVUXkHuDHIvJ94DjgJGAr\nIMBJInIinhA5B/iSO2dTOX0czIMwDJ+JMmfZ6pXGZOZg5tlcCnxTRHbh+UtucfW3AE2u/pvASgBV\n/Q1wJ7AT+AVwsaqmnE/mEuB+vGi3O13bsvswjHLJp8GYOcswKo9lfTYOWQppMBOl2ViAgFGLWNZn\nwzhIghrMgQMH6O3tBSZu4qRpVMZkxhJxGocs8XicSCRCKpVCVbn11ltpb28nFotlyniPx1b0NCYr\nptkYdU+u36XUSLJYLMaZZ56Z2U+lUhOqTVgqGmMyY5qNUdfk+jnWrl3L1772tcz+pk2bCr60k8kk\nGzZsyOyHw+EJ1yYmQqMyjPHANBujrkkkEvT395NKpejv7+eWW26hv78fVaW/vz/jhyl07tCQl6BC\nRDj//PPtRW9MOpJJWLPG+5xITLMx6pqmpibS6TQA6XSaKVOmlHxuro+kvb29WsM0jAkhmYRFi2Bg\nAKJR2LgRJur3lGk2Rl2zf/9+QiHvzzgUCjF37lyi0SgiMqoAMR+JMdlJJDxBk0p5nxMZ4GiajVHX\nxONxGhsbs7ST9vb2kmfhm4/EmMzE455G42s2E+mStEmdRt2TTCYtxYthFCCZ9DSaeHxsJrRKTeo0\nYWMccphwMozSqZSwMTOacUhhKWEMY2KwAAGjZhiPtP6VTglzMGOu9P0Wu56tAGpMOKp6SJRTTz1V\njdqlr69PDzvsMA2Hw3rYYYdpX19fzfdzMNeq9P0Wu954PVtjcgJs0wq8g02zMWqC0TSOQr/My/3F\nXslw59wJpeVoSbn329vbm7mPsWghxZ6fJfg0agHz2Rg1QXCCZSQS4aWXXiKZTBZN+T9W/0ulwp1z\nJ5Q2NTWVfG7wfsPhMLfddhtDQ0NEIhFUlVQqVdY9FUviaQk+jVrANBujJvA1jgsvvBBV5aabbmLR\nokUkk0l6e3s5cODAiF/mE/2LPXdC6f79I1YmL0hQwzr//PMZGhrK3Mfg4GDZ91RMY7PJq+NPraSI\nqSkqYYurh2I+m9qgu7tbFy9erN3d3XmPr169WsPhsAIaDoe1o6NDo9GoAgpoQ0NDxucwmi+ir69P\nV69eXfP+n+B1GhsbNRqNmn+ljunrUz3sMNVw2Pus96+QCvlsRjWjicgU4CGgEc/s9lNV/Y6InAjc\ngbdc83bgf6vqgIg0Ar3AqcB+4C9U9QV3rVXABUAK+Jqq3u/qzwB+AISBm1X1u66+7D6M2qWnp4eL\nLroIgH/9138FYPny5VnzXnJNPkAmWSaQMVvB8C/2fHNmxiPEuVj/B3MdwOYB1TH5UsTY11iaz6Yf\n+JSq/peINAD/LiIbgG8C16jqHSJyI54QucF9/k5VPyQi5wBXAn8hInOBc4CPAscBD4rIya6P64HP\nALuBR0TkHlXd6c4tuY8KPA+jiqxfv37E/rx580YIBf/F29TUxI4dOxCRzDnpdJre3t7MS9j/9M1N\nwf3+/n7S6XTGee8fq+SkznL8P8X6zb2OCZn6pZZSxNQU5ahBwOHAr4DTgNeBiKuPAfe77fuBmNuO\nuHYCrAJWBa51vzsvc66rX+WKlNtHsbGbGW3i6e7uzpjDAO3u7h5hNlu9erWqZpuWGhoaNBQKZc5r\nbGwc1ZSWr69i7atNJU1u1TQNGpWhr0919er6N6GpjnPos4iEReRR4DXgAeA54E1V9e0bu4FZbnsW\n8LITZEPA7/HMYJn6nHMK1TeNoY/ccS8XkW0ism3fvn2l3KpRRebNm0dbWxstLS10d3ezfPnyjNks\nHA5nIqWSySSXX355Jqw4nU7T3DycLWNwcDArSCBf+HEh5301ggpKCVWuRL++afCyyy7LBE8YtUks\nBqtWmfksSEmhz6qaAuaLyFTgZ8BHqjqqCqGqPUAPeLnRJng4hyS+6aipqYkVK1ZkzGXz5s0D8vsr\nFi1alDGBhUKhjBDaunUrkB1mXCj8uKmpiXA4DEBDQ0MmlDoejxMOh0mn00VX5uzp6WH9+vWcffbZ\nLF++vOj9leIbqkT4cT6BNR7mNsslZ1SCsubZqOqbIrIJz6Q1VUQiTrOYDexxzfYAxwO7RSQCHIXn\nxPfrfYLn5KvfP4Y+jBoi+CIWEdLpNOl0esSLMuivWLNmDQMDAxlB8+lPf5rLL7+cRCJBKBTK1Pua\niq/BBOt7enq4+OKLSaVSmWM33XQT69atY+3atRkfUNAXFKRQIEM+ShUAlQgmmIj5MpZLzqgUo5rR\nRGSG02gQkcPwHPlPApuAP3PNlgJ3u+173D7u+L85u989wDki0uiizE4CtgKPACeJyIkiEsULIrjH\nnVNuH0YNEXwR+5pE0FyWj6BZrbGxkcsvv5xYLJZZt8av98/PrW9qauKSSy5haGgIVSWdTmfNYVm/\nfn3m2NDQUF5zVr5AhkLkMwMWIhaLsWrVqoOOWhvP+TITPZfJmESM5tQBPgbsAB4DngD+r6v/AJ6w\n2AX8E9Do6qe4/V3u+AcC1/o2nr/naeDMQP0S4Bl37NuB+rL7KFQsQGD8yXWK+wEBozm3CznBC83R\nCbZfvXp1VjCBP3clOIbRHPWFggvKHe9kwPKqGVQoQMDWszGqSin2/kJtgvVASeYc3+zT399POBzm\nuuuuY968eVnXL2VMpfpsCo11Mvk4zGdzaGOLp5WJCZuJpZhA8YVIJBLhzDPPZObMmSxYsCAroGDp\n0qXcdNNNpFIpwuEwV1xxBatWrSq7r2q8NIP3EA6HERGGhoYm1MdhAsKoFLZ4mlE3FHMyB30CqVSK\nu+66C4BwOJzxuQwMDABkOcebmppYs2ZNSRMkRxvDwZLrmwLPPD2eEWNBzKlv1CImbIyqUyxiy3ew\nHzhwgKCW7QcUiAjRaJT29nba29vzhlGX8jKtZthwbgbnoGYzERmWJypEuhokk166l3jc5qzUOyZs\njLIp10RTLGTXj7Dq7e3l5ptvzuRBi0ajXHvttezYsSOrbSwWy4RHp1IpDhw4kJW+ptgYIpEI6XSa\nSCSSNYaDNTnVWm6zybKkQDIJixYNp33ZuNEETj1jPhujLMox0QSd7LlO+kLX7u3tBWDBggXs2LEj\ns85L7jo28Xg8Y15rbGxk06ZNRXOfJZNJTj/9dAYHB2loaOC6665j//79Y9KSKk01/CuTwWezZg1c\ndpmX0DIchiuu8GblG+NLpXw2E576f7yKhT5XhmAuMxHRjo4OVR0Z/lssfLhYqHBfX19mWQERyQph\n9vOmqap2dHRkjhfKqRYM1e3o6MgaTzgczhT/OqFQSBcvXjyu4b0WWlyYyZaqv15hvJYYMIwgvjkq\nlUqhqtx6660ceeSRXHPNNaRSKRobG9m4cWPeiZH+cgKFNKOenh4uueQSBgcHs871/Ta+OSiZTLJ3\n715CoRCqmnUsUSTbc5BUKjWiLp1O8+CDD7J58+YxazilhkD77V566aVJ418pl9H8MbGYZzozn80k\noRISqx6KaTaVI6hVhEKhrEmUoVBIV69eXVCzKZblORKJZJ1DQAvp7u7OaD0NDQ0jjvkUy/ace/2g\n5hTcz9WiSiWopUSj0azJpEGNZbwWS6vlyaamtdQPmGZjVJtCvg/wklv62kFQSwiHwzQ1NbF//346\nOzt59NFHmT9/Pvv378/4WvKFML/00ktZC6PlsmPHDlasWJE3as2/tq8p5MuhFovFWLZsGd3d3agq\noVCI5uZmduzYwdDQEJFIBBEhlUqN0KJK9X34y1eratEQ6GC0GMCFF17ICSecUHGfzUSFP5cSQWYL\njB2CVEJi1UMxzaY88vkScn+Rt7W1ZWkZoVBIFy5cmPVLPV96GP8Xd/CY/wvf1y6CmlM0GtWWlpYs\nDcov0Wg06zrRaFQbGhpURDQajRbUKPyx+UtOh8Nh7ezszNIEyvGn9PX1aWNjY2ZckUikJM2mWn6a\nQhpktSlVYzHNpn7ANBujmhRKwBicvPj0009nLdksImzevDmjefiJL3Ov42sNGzZs4N133wW8Hz1f\n+MIXeOedd5g/fz5vvfUWO3fuZN++fezatYtt27ZltJVIJMKSJUuYOXNmZu6N34eqZrI5p1IpHn/8\n8azs0mvXrs1EyO3fvz8z/lQqxTXXXMMvf/nLTMSbv6ZOvkzV+Z6Xfy0RYdmyZZmx5WoslVpOuhiV\nDH8uZ65LqRqL+WMOQSohseqhmGZTHrlaTEdHR5YmkFvC4XCW5iEieTUbfz/XX4LTBoLaSe7xQtFi\nwbFGIpGsa0cikYKaSnd3d5Yfx/c3+e38+wmFQiVpNrUWVVYJn025GohpLLXHwf4dYJqNUU2Cky1v\nvfVWbrrpJqLRKEuWLOHuu+/OaC8+s2fPZu/evQwNDREKhViwYAEXXHAB8+bNY+lSbzWIBQsWsH79\n+hF+Fx9fM0in0yOOi0jWkgO5UV/BPoIRbalUihUrVnDKKacAZGlZ+/fv5/rrr+eSSy7JRNLF4/GM\nppS7pk4xDaSa2spY5sx42kiMeDx2UFpDub4V01hqi5pKXVQJiVUPxTSbsZFr++/o6Mj61U+OdjNn\nzpxMhFowIsv3yeQ7L7dEIpERmk2+iDQR0YaGhhHRXL7Gkqs95S43ENR4CvlqfK0u6Guq9Xk4ldQu\nTFOpbyrhu6NCms2EC4HxKiZsxkahQIFg+HOhIiIjHP7F2vqfbW1t2tHRoXPnzs0SFL6gKyVkubu7\nW2fPnj2in7a2tpLX1PEnl1Y7RLkYY3lZrF7tCQfwPjs6hstYht3X513TBE39UQnzbqWEjZnRjKIE\nzUNNTU2ZdDLg/VAphu/MHxwczAprbmhoQFUzyzZ/61vf4oc//GFmmYH77ruPVCpFJBIhGo1mwpHB\nM4Pl9hsKeQvO+o7wZDLJ1772Nfr7+0eMaebMmQWXJsi970QikclGPVHZnEeGin+eNWuKm6jicS+X\n2MAARCJw883gx3Hcdhts2lSeeSsWM3NYvTIewSglM5o0Ao7HW555J/Ab4OuufjrwAPCs+5zm6gW4\nFm8VzceAUwLXWuraPwssDdSfCjzuzrmW4ZxtZfdRqJhmc3D09fVlBQc0NDRkOddztY1QKJQxey1e\nvDhjPvNT3OQzXXV0dGSFOPvajN8u13HvhzfnrgC6evXqvJqUb4or1RQ2XpMvSxmHFyr+mEajqiKq\n0ehITSOogfjbHR1ee/CKiFdvGKXCeJnRgGP9lznwXrzlm+cCXcBKV78SuNJtLwE2OIHQCjysw4Lj\nefc5zW37wmOrayvu3DNdfVl9FCsmbA6O3Be4LzSCJeiPaWtry5xbTJXPnXMTNKfle6n7Qsk3tRXK\nrxac8+ILms7OzjH4P/qyhN1Ezcjv61NtaRkWGqAaeMQFfSt9faoNDdnnjbLKtWFkUSlhM6oZTVVf\nAV5x238QkSeBWcBZQNw1WwckgEtdfa8b5BYRmSoix7q2D6jqGwAi8gBwhogkgCNVdYur7wXanDAp\nqw83VqMESl3N0t9vamqioaEhayGz9vb2rLxm/vwW8ObQJJPJzPGlS5eyc+dODhw4kJn7EoyUCYVC\nWTnRRIS1a9eOGENuJuj29vYR9xaLxdi0aRO9vb3s3bs3s/Ln+vXri86byfdMchdim5hVN71U+25K\nUoZ77/WOxWL5o8bA+/zc58CtSUcoBC6pgmGMK2X5bERkDrAAeBg4JvBy3wsc47ZnAS8HTtvt6orV\n785Tzxj6MGFThOBLO19a/dwwybVr17JixQr6+/sJhUJ885vf5K233gK8EGN/oufjjz/OxRdfnJW2\nZmhoKHN80aJFWeHOW7du5aGHHuLZZ5/N1Ocmxkyn01x11VU899xz/OAHP8jrq+nv76e3t7fgxMlg\nip1FixZlBE0oFBox0XGsIaKVTuWfbwJlIgHD7if/GQiqw6HI8bjnn0mnvc+mpuG1YCIRz4eTSnmf\ndbq8jVHnlCxsROQ9wHpghaq+FfwVq6q++aNqjKUPEVkOLAc44YQTqjKueiFXi/Cd3sFf+LlZA4Jz\nYtLpNN/73vfYvHkzQOZa4XA440T3CWZp9q+ZKyhuv/32Uce8a9cuurq6Ch5Pp9PccsstmUCD66+/\nnuXLl49oV8q8mXwZE0YTHpWcw5BMQm8v3HrrsFDwFwuLx8H7d1M8y7FnHQyHlXg8FHgeKVSFdFrZ\nsSOc0XQALrwQTjjB5r4YE0dJwkZEGvAEze2q+s+u+lXfdOXMZK+5+j14QQU+s13dHoZNYn59wtXP\nztN+LH1koao9QA94i6eVcq9s3RR1AAAgAElEQVSTlXwpXfwfDE1NTZlPv96P8AoKiVQqRVdXFzNn\nzhyRcNInHA5z4YUXcuSRR3L55Zczf/58wuFw3omalWBoaCgzjksuuYR58+aNMI299NJLRCLen3o0\nGs07QTNfepfRtJbRBFQpWk9QyAwOel4VgAMHvHr/tFDIFxz+M0yTTivgfU+9vS8yODgLCDM4OMje\nvfuIRmdmVrlsbzchY0wwozl18H5K9QJrc+qvItt53+W2P0e2836rDgcI/BYvOGCa256u+QMEloyl\nj2LlUA8QyI2s8udukJPMspT5MMEJl37CSX8iZ2dn54g0//4Ey9GuXUoJXqOhoSHrPvx0M/nuORKJ\naEtLS9ZyBLnPxw90yE06WmgC6GiBD9mpcR4bMdelr0+1sTHbeR8sDQ3DUWX+vBlIKQwpqIZC6Uxk\nWUfHOoW3FQYU3taOjnU2P8aoCIxjNNqfuH/mx4BHXVkCNAEb8cKSHwwIDgGuB57DC2duDlzrfLxw\n5V3AeYH6ZuAJd851DIc+l91HoXKoCxvV4Rdl7oRMEdGWlpaShUGwXVtbW2bGvp9DLDgZs9LFj0Lz\nhUJnZ2fW8aAwCU6IDAqkzs7OEc8lV2jkm0xZaIJr7gqlixcv1ra2Ng2FPq6wUkWWq8igQlohrY2N\nngDo6MgWLsEQZb90dHjRY5GIaiik2tCQ0nB4UEOhdE7UWZ9Go6eryF9rNHp6TeRmMyYHlRI2pUSj\n/bt7uedjUZ72Clxc4Fq3Arfmqd8G/Lc89fvL7cPIJteUE4vF6OnpyfhtwDN97dixoyQzl7/uix85\ndt999wFkzHMHDhzg7bffrtr9vPDCC7S0tGTuJ5FIZNavAW/dGx/fNBYMTkin03R1dfHBD36QefPm\n0dvby69+9asRUWrxeDxj/gPPxBg0mx04cIDe3l5uuOGGrIi8iy66yPXeivc7KepMY2H8f6P+fiWR\nEPbuzb63o4+Gffuy6/buhRUrPMd/OAzXXRdi3rzQiCAC71mscWNfc8is9mmUQDlpu6tJJSRWPZRD\nUbMptiaNb/b6oz/6I21raxuhAfjaTktLiy5cuDBrXktbW1uWppCb78zXcoJ1lSzBOTi5K3A2NDRk\nzb/xzWO542lpaRmRwTqY3bmvr8+ZC1sVVmok8gnt7u7Omr+Tu17O4sWLXfsfKSSdyUszGo2/HQql\ntLMzaBrzSiSSPSemocHTbIKpZ2xCplEWFUhuh6WrMUYj14Hd1dXFE088kfVL/6mnnuL555/PBAaI\nSMaZv3XrVkSEKVOmsHbtWnbs2EFXVxc///nPM334f0hBhoaGmDNnDi+88ELJY506dSp/+MMfSgok\nUKdB+WHcwTV1BgcHufHGG7ntttvYtGlTpv5jH/sYjz76aGb/uOOO45FHHsm6bjBK7ctf/jKDg38D\ndLp7GmTHjjs577zzuPHG9wNfYmBgPytWKBdc4M1dmTHjr4HTgMacEQ9HkHn9vM4117yPnGhvVGHZ\nsuF9fwrRunVkHP0WtmyURS0tiVoJiVUP5VDXbPKtD0OOtoD7dZ/vWDU1lbEU3/dSrE1bW1ve9Xca\nGhpGrM3jp7Lxn1s43DFCI5kzZ6+2tOwP1AePez6V4H528epF0rp4sd9Ws84t9MPTHP3GmDHNxhgP\ngitTvvzyyzz55JMF26rTJnJDmf1j/vFa4dOf/jTf//73i7Z55plnMhkPgqTTafbv308ikaCrq4t7\n770XVeWrX/0xO3Z8FniWVOoS13rYXfnCC+/jhRd8LWWkG9N7dCPrw2Fv7pEqRKPC2WfD5s3eRM1w\nGL7xDZg6tbBJ3RJhGmOmhhYYklp7iVSL5uZm3bZt20QPo+rkLipWKB1MveDPBcr9Ow0GBeQjHA4j\nIlkmNv96U6ZMyUzAXLNmDf/n//ycdPpc4AK8qWe5AiOfgNHAseKEwyMnVdaKz9YwRkNEtqtq88Fe\nxzSbSUTujPalS5dmfDYAbW1tvPPOO8yfP58tW7awefPmmtNYclFVpk6dylFHHcURRxzBk08+ierw\nZFJfGL3nPe/hiCOO4OSTT2bu3LmAFx3m47cLhT7OZz/7PR5/vIXeXtiy5Suk03+FNzlSGBYs5GzD\nsMDRwL7fLj8i+SdVmrYyybFfEyMIjd7EqBdyAwLAmzEfCoVQVU4++WTuv/9+AB566KGaEjSLFy8u\neOzNN9/kxRdfZOfOnSOOiQh/9Vd/RX//Kbz66vls2SIsWLCAvXv3jtB8VE8jlXqQu+7671x0Edx4\nIzz66FF4YcnBfwVf6BRDgMKaFXgazVln7WXp0l4gmbdNMplkzZo1JJP5jxt1iJ859bLLvE/7bgHT\nbCYFwQSbwZQr7e3tHHnkkZn8Yl1dXWzZsoWHHnpogkc8kmeeeaakdrkCUlW5997XGRi4D4gyMDDE\nRRdtAf4H8HXX6nhUBS+Pa5TRzWTB7UJCR4Eh5s9/kGj0DI47Dk4+Ga65xgv88Xwxz/HDH85jYGCA\ndetG5k6rqfXhjcpRSxFgNYQJmzon94X11a9+lUQiwXHHHQeQFe4L1KSgAcoKkw6iqjz1VAteuHHY\nldPHcKWgoMnqwTsqikjI5SMTIEUotI4f/ehjWe+RtrZh60kicWfR3GljSf5p1AHBpVItXj2DCZs6\nIzcjQPCF9e6773L11VdnzEc///nPJ9nLqxUvl+vrwNHAHwGLUZ2BZwYr3Wk/TL7IsjRTp/6GcHgO\n733vkcyfD52dwuOPw8UXC6mUEomkue66/0EsNi/rzGxfzMjknkHyJf80JgE1FAFWS5iwqSPymV2a\nmpqyTEtBP8Xg4GDNajKl4QuXBJ5ASJA/WowCdbkEHfz5TGdk6t988yfAd1m9ujuwbEGSZcueBU6n\nvf39IwSNT/AHQbH132tqfXijslgEyEgqMVmnHkq9TuoMJnrMTQ7Z0dExIs3M5CitCusVBtVL+ZIO\nfGqez5GTJ4tNrBy570/OHHTlbTcGL62N/z1kZ3HuzrtEdLFM0OPKZJkJOlnuo47BJnVOfvL5Y8CL\nwAqHw+zcuXPECpf1QVBj2RLYPxL4JF4S8LBrm2+OSzEtZrRjWmB/A6HQao4++mxee+1ONy6YMmUK\na9as4aWXXsqYK/v7+7n44oszi7EFF22rCT+MHw3l+wz8VdjqjclyH4ZHJSRWPZR602z6+vp08eLF\nmTQyIjJi7ZaZM2eOSXOYPn36BGkrKxWWOc1hUOFdp8EMBDSX7BQwpZXRNJzstDONje+4/lJuHKsV\nhtf18VP7hEIhDYfDGgqFNBqNZtYBamhoGLGuTjDx52jr4BzkH8bov/SDC+DUcvbO0e6lXu5jksN4\nrWczWUo9CZvgC29ylNaAgOl3n0EhUIp5rByhk++6nnAJh1N67rnX6bDw88xlIqIdHR2qOpwpOle4\nd3R06OrVqzPr9wSPLV68uKBgqYhpzV8Ap6HBW/gmGi38kq5APqwR1yvHlFVK+1LGWOn7MMaECZtJ\nKmxyU+YHSyVWupwYQbMhIGCGNNsXczDCJZ+w8X0v69TTmIbU06CWqcgqbWn5us6ePXvEOHOFwOrV\nq7OSj4ZCIW1ra8sstdDZ2akNDQ2ZNsHlCXLJtxBb8PseVePp69OhxkZNgaaDN+yEY6FzMi/8g/F7\nlPvCL7V9qVqL+WwmnEoJG/PZ1BiJRKKoH8bPBuD9DdQ6rcAmhlPuK/mTVpQTquyjjEwtA/Aw8A3C\n4UdQ7UF1IaqbEHkYVeWRR0b2tXDhQs4991wSiQTgRYnF43EaGhro7+8HvCi/u+66K3NOY2Mj1113\nHevXr+fBBx/MWngt10dTKMQ576ROGBEy+2JvL7P6+wkH7hZgxOpruSlS/CRsixZ5WT9DIbj+eshE\n15VAuRMUS21f6lwUi+qaPIwmjfBW1nwNeCJQNx14AG+55geAaa5egGvxln1+DDglcM5S1/5ZYGmg\n/lS8pZ13uXNlrH0UK7Wq2eRbVpgimkIoFNL3ve99NaCx5NNgfuRKq6vzl0LO1V4O1kwW1GKGNSWR\nA3ruuddpR0eHRqNRDYVCGolE9Nxzz9UPfehDI5bCnj17tnZ2dhY0c+Uunx0sIlJwqehSvmdVT+P5\neCikK0GXi+j2lhbPPJajFVzZ1qZvgw46zSaj3fjrS3sd5NcoVq/OXs8gHC5PS6iWZuO3Na2l5mG8\nzGjAQuCUHGHTBax02yuBK932EmCDEwitwMM6LDied5/T3LYvPLa6tuLOPXMsfYxWalHY5AunbWlp\nyftyC5psaqv4YcpDmu0rCTr8xyJYcgVM7hoygwHBNux/CYfD2tbWlnlWIlJw5VDfR1PIzLWrs1Mf\nFtH1oK055zY2Npbn/Pd9Lh0dmZfrY93d+YWILxTcODo6OnQZaD/oULBd0PxUyCzV1zdySdBi5rdC\nY6+0z8aoG8ZN2Hh9MSdH2DwNHOu2jwWedtvdwBdz2wFfBLoD9d2u7ljgqUB9pl25fYx2D7UobIIv\nuVAoVKNBAdmO9GHh8rjCPh3pjM8VDAcjaHKv9WsdqT2NLLmCpZB20tbWlnH4R6NRFZHhpZ67u1UD\nQmAwFNIrnc/m7xcu1DdaWrw2xfBfut3d3prP/k35Gsnq1ZoWyfSTOS6SpRX09fXpt8NhHXTH03na\n5NUo/P4XLjw4YWMc0lRK2IzVZ3OMqr7itvfiZTgEmAW8HGi329UVq9+dp34sfbxCHZFMJtm6dasv\nMBGRGpwz0wpsxEteCfAqMJORfpd8iS0PBs3Z3grcAtxc8IysmTuBLAoiQijkjTcSidA8OMgn0mk2\nh0Js2LCBe++9l1AoRCqV4jRVPjk4yN0rV/KRAweYFriTSDpN58yZsGABXHSRV7l1K2zYAGee6a0L\n7fsdEgloaoIVKzxfif+a9/F9GU1NiP/9e4P1/BennQYHDsDjj0MsRiwW433f+hZy9dWoKhIOwymn\nwAUXDPszYjFYuxbWr4ezz/bq/DkqkYhXUiloaBheb9owxpGDDhBQVf+XY9UYax8ishxYDnDCCSdU\nfFxjIZlM0tXVxd13350RNACpVIpwOFzkzPFkGXA28D7gMIYd8ce54wcrTHJRsp39CqRp5afE6STB\ny26KZX6CInEIuA3oxZuW6T/jD3/4w5wejXL1o4967dJp7uvv51XgV6kUp+AtnRZWJf3QQ7wZGFWG\nhx6CDRuyRit33QV33eU53yMRT2D4i9TlChmfUMgTTL29w3Ui8JnPwIwZ6O23e3Vbt3r9z5vHB3/4\nw+FzRWD7dk8YzZs3HAiwYoUnXDZvhqVLhx31MHL1NsMYZ8YqbF4VkWNV9RURORYvgABgD3B8oN1s\nV7cH74dnsD7h6mfnaT+WPkagqj1AD3grdZZzg5UmmUzS29vLTTfdVFCDqQ3NZhnukQUY8dqtEMGv\nJO327wauopUtGQEyACxyreIMp+FM4AmUdrJzPl+E9wvj18ALAKkUr7q1cKJ4f/Rh4E9zRuKvYhNy\n1w/WA7BzJwX/iNJp7+U+GqEQ/OhHnqC46abs+vnzSV91VdYSbr+75RamtbV5106nPUGTdka3YLRX\nbhQYZEd75a7eZhjjzFiFzT140WXfdZ93B+ovEZE7gNOA3zthcT+wWkSmuXaLgVWq+oaIvCUirXgx\nq+3AD8fSxxjvY1xIJpOcfvrpNbgsczCL8rl4aWIOd8fypYk5mJ76iPNLEsQBJU6CBKezhY/Qyg+I\n8xAJXmcLv6EVuAaYwnAu53a8P4IonqBIufq3gKlk53z2txe44pOrPwVTcAbPzz2WS6FUnnlxK4Si\n6m1H3L/cJZcMax3gbX//+6CaNcbkccexpKnJOzcU8sxgql77YMhwbihxe7tXLPOwUSuM5tQBfoLn\nDxnE849cADThWS6eBR4Epru2AlwPPIcXztwcuM75eOHKu4DzAvXNwBPunOsYDn0uu49iZSIDBNra\n2kpwxE9EBFlwcmVuOVjH/rCDv5X/0Lc5TAcJ67s06rtEdZCQvk1Il0EmIutd0PWgAwHHfMZBH3Ci\nBz/TBerzDWZExFeRa412ThpGTrLMV+bOVW1pGQ4/DodVFy/ODkf2SyikKRcIMAjaFQ7rY93dnsM/\nFPKyB3R362Pd3bpp8WLvWBCLAjOqAJZBoLwyUcKmr69PZ8yYUQMCBvXykiV1ZFhyJYWLalBotfIf\nuoFP6aDnCtchV9S9UJ92n4Ve+LlCJ7eUO7jRhEuusMonwHxBkyqlTxEv+iw4fyYoQMJhT4gEjr3Q\n0aHrOjq8qLickOYXOjpqI6u0cchQKWFjGQSqyKWXXpq1mNn4swxvaeQPAQ1kR5GVmkW5NDwzWYIE\ncbYQA16ilevYyPeJks4yffmfYeAkd74GRqKB6xYbmS9Fg+10lHNKMX3lM7XlHs9Ej6nmaREcpMLQ\n0EgH/bx5wyYuyDJ3vR/PbJghYB77JUx8VmnDGAuVkFj1UMZbs+ns7JwgzeVxV36thc1jpWsyrfTp\nSlZrK305+/+Rpb14ZrKQ9hPRZXxcAd1eQJMoZP4ar5I7pnzayNuzZ2eNMyWSPVcGPG3l3HPzm8T8\nEgodfBLJgHmsZtbLMQ4ZMDNa7Qqbvr6+cU6a2arwn0WEy9hKK30ZX8vbHKbL6NZ38RJCDiH6FCfq\nc8zS1zk86wXuHS9s8hqrCWw04VGu4Cp4Xiikunq17urs1N2zZ+u+hQuHMwC4SZgqMjw50j8WnKkv\notrWVhUfSsWWKzCMEqiUsPGd8ZOe5uZm3bZt27j09eUvf5kbb7yxSldvZdjI8ivgauC9DBt8SjUo\nQSvJHNOXxzJ6OJv1vMNhfIF7iZAmDQwRoYGhEaauIOWYwSqFf6fBOy509/7Y8o5TxCuNjfkX6hpt\nMa+enuEos0LXMIw6Q0S2q2rzwV7HfDYVwl93/s0336S7u7sKPbTiBeHNp7Anodh+8EpJ2unlPG4l\nQooBoixiIwB/RRd/yl1Z7f0XdwNDJVx9fASMT1DQBOvybfu+lnRg32/z9pw5HPHjHxcPFY7FPAFS\nqM3y5dm+GBM0hpHBNJsK4KeKP3DgAJV5nsH5L2fiTSc6lrFoL9lX9YXMbUQZQNDMy/e/OJz38k6m\n7WhO8okinxYTPAZeAEKIYeES3KehAb7xDVJdXVnhErcvXMj/+uUvqzl0w6hLTLOpIbq6unj33Xcr\ncKVleNOYmgm8HgMU3881iy2jhwu4hWm8wVH8nqPZl/US9p0+AhlBU6tCBkYKmHzmuoeBSxsauPUb\n3+DE732PtDNpybXXDucvi8X43jPP8KG77uI4vKxrkblz+V/jcxuGcUhiwuYgufTSS7MW1RobrcAa\n4PRAXekz+FtJsoaVLOShTOu9zGAm+0a0zRUy+ZgoIVNIW8nNmubzh6YmQtOmMWXXLkJ4aW2+Acy/\n4AJea2vjP956i9OB9+dJ1fKJzk4+uWFDZuGyTZac0jCqigmbMeIn1By7oPHnwHyEbC1GMqldXqeJ\no9nvUrzAGlbyMR7jHaawlVY2cCZruJTpvJllYFPICJrRNIFaotCYfB/LL4Bj58zhfUNDHPjSl/jg\nlVcCcNell/LI1VeTUOXXU6Zw3oIF2StgtreT6z2JxWJs2rSJRCJBPB63uSqGUWVM2IyBZDLJJz7x\niTITZy4DVuFl4TkMb5JlEMmYvU5lOyFShPD8DYKgKH5O6GnAn3JXliO/lCmauR6fiaCYryUfKeAm\n4B9E2DFlCht//GNm5QiGtiuv5Ji2Nt6TSHB1PE4ikShp4mPMpe83DKP6mLAZA11dXSUKGt/R/wla\nmUqcOwL+lJv4Oms5htcIkea/OIITAkv7+BpKBFD3Oi5kYqpFch35hUKOfZ4/8kie+MMfSAUCLF4F\nNs+ZQ3zVKj6/fz9XF9FAcgVHNBrNaDbxQuvbG4YxbpiwKRM/xDk/wSiyU/AS3YdoJckmPkkUL/X7\nEGEayBZW0/kdkD+Mt9ALuhYETTFhEvzMbff6rFns3LOHRmBdOEz7L37B+/AE+b333ouq0tjYyMYf\n/7hs7SMWi7Fx40YzkRlGDWGhzyXS09PDLbfcwvbt2wtoNctopZ04m7O0l7NZz4k8z8nsKmnCYy1r\nKz757kFz6h8R4Xeq7MBbBuDfw2H+3znncPzDD6P/83/ywSuvzAjuXIFQqN4wjPGnUqHPJmxKoKen\nh4v8pYAdrXyUOEe7NVjeyzKW8iMuIew0llc5mpm8nnVOrQsRKK5JBenHW7DMJwV8GW/RsX8Ph+na\nvBmAXrcaZXt7uwkOw6hDbJ7NOLJ+/fqs/VY+ykaeJ8pTDBDl63yPG/gKYTQQDeYJmsouQVZ5clO8\n5PtM4y0eNAg8A1yFt0KmPyvoP4FrwmH2n3wyH/7wh+nq7MwIFhMwhmGACZtRSSaTHH744bTyUdqZ\njhdJNpUoO4mghHjXCZrC0V4TLWhG01KCAmcH8E8ML7k8c+ZMpk+fzuzZs3n++ec57bTT+MJHP8p5\nTU3s37+fx9xnl5m8DMMoggmbIiSTSVbF45wzMI3zeIMo3rLOKby1WPyXdLjINapNMUESnMCpwBCe\n/+QPwEvAfx55JO+ZNYslTz5JCBgS4fqPfIT+U07hyH376D77bJYvX17tWzAM4xCgboWNiJwB/ADv\nXX+zqn630n0829vLfQNDNPJq1rRLX7iMLUNZeZTiUQuau3wB4wvDFNAzfz4LfvQjgIzjPR7UQpJJ\nSCSIxuPcYtqJYRhVoC6FjYiE8VIgfwbYDTwiIveo6s5K9vORvVGiSObF7QuVSqfRL8XMlcubwLPA\nbaEQ//XFL/IP//APWYklfQESicf5SkCA5DV1xWKWodgwjKpSl8IGaAF2qerzACJyB3AWUFFh89TM\nc/hv3IRwgFDA+Z9ZFrgEiq2fUigVPnjO+LdnzmT63/wNW+bNGxEKPB0vF/RphTo2AWIYRg1Rr8Jm\nFvByYH83ed67IrIcb2YlJ5xwQtmdnNQeY8mtGzlnoJe/5FYaGMjWHvJQSEsJRngFfSnvzpnDEatW\nITm+kUaGQ4tjWFSXYRj1Tb0Km5JQ1R6gB7x5NuWeH4vBmkSMRCLGL95s54REL3+89cYsgTOqSe39\n74ef/CSzoJbEYhkTl8TjHGFCxDCMQ4B6FTZ7gOMD+7NdXcUZtkbFvJJsh64uePppmDEDAHnmGThw\nAD72Mfjudwuv8jjyooZhGIcE9SpsHgFOEpET8YTMOcCXxqXnWAx+9rNx6cowDGOyUJfCRlWHROQS\n4H68KN9bVfU3EzwswzAMowB1KWwAVPU+4L6JHodhGIYxOqMFVxmGYRjGQWPCxjAMw6g6JmwMwzCM\nqmPCxjAMw6g6h8ziaSKyD3hxlGZHQ86KZ/WBjXv8qMcxg417vJlM436/qs442AsfMsKmFERkWyVW\npBtvbNzjRz2OGWzc442NeyRmRjMMwzCqjgkbwzAMo+qYsMmmZ6IHMEZs3ONHPY4ZbNzjjY07B/PZ\nGIZhGFXHNBvDMAyj6piwAUTkDBF5WkR2icjKGhjP8SKySUR2ishvROTrrn66iDwgIs+6z2muXkTk\nWjf+x0TklMC1lrr2z4rI0nEYe1hEdojIv7j9E0XkYTe2fxSRqKtvdPu73PE5gWuscvVPi8hnqz1m\n1+dUEfmpiDwlIk+KSKxOnvc33N/IEyLyExGZUovPXERuFZHXROSJQF3Fnq+InCoij7tzrhWRg12t\nvdi4r3J/J4+JyM9EZGrgWN7nWOgdU+i7qsa4A8e+JSIqIke7/fF53qp6SBe8rNHPAR8AosCvgbkT\nPKZjgVPc9nuBZ4C5QBew0tWvBK5020uADXhrt7UCD7v66cDz7nOa255W5bF/E/gx8C9u/07gHLd9\nI/Blt/0V4Ea3fQ7wj257rvsOGoET3XcTHodnvg5Y5rajwNRaf954K9b+Fjgs8Kz/shafObAQOAV4\nIlBXsecLbHVtxZ17ZhXHvRiIuO0rA+PO+xwp8o4p9F1VY9yu/ni8bPkvAkeP5/Ou6j9wPRS8VdHu\nD+yvAlZN9Lhyxng38BngaeBYV3cs8LTb7ga+GGj/tDv+RaA7UJ/VrgrjnA1sBD4F/Iv7Q3w98I+Z\nedbuDz7mtiOuneQ+/2C7Ko77KLyXtuTU1/rz9pdHn+6e4b8An63VZw7MIfulXZHn6449FajPalfp\ncecc+1Pgdred9zlS4B1T7P+jWuMGfgr8MfACw8JmXJ63mdGG/2F9dru6msCZOhYADwPHqOor7tBe\n4Bi3Xegexvve1gKdQNrtNwFvqupQnv4zY3PHf+/aT8T3cSKwD7hNPBPgzSJyBDX+vFV1D3A18BLw\nCt4z3E59PHOo3POd5bZz68eD8/F+2UP54y72/1FxROQsYI+q/jrn0Lg8bxM2NYyIvAdYD6xQ1beC\nx9T7SVEzoYQi8nngNVXdPtFjGQMRPJPDDaq6AHgbz6yTodaeN4DzcZyFJyyPA44AzpjQQY2RWny+\noyEi3waGgNsneiyjISKHA38N/N+JGoMJG29Z6eMD+7Nd3YQiIg14guZ2Vf1nV/2qiBzrjh8LvObq\nC93DeN7bx4EviMgLwB14prQfAFNFxF+kL9h/Zmzu+FHA/nEes89uYLeqPuz2f4onfGr5eQN8Gvit\nqu5T1UHgn/G+h3p45lC557vHbefWVw0R+Uvg88C5TlAyyvjy1e+n8HdVaT6I96Pk1+5/dDbwKxGZ\nOYZxj+15V9ouW28F71ft8+6L8J13H53gMQnQC6zNqb+KbIdql9v+HNkOvq2ufjqeL2KaK78Fpo/D\n+OMMBwj8E9kO0K+47YvJdlbf6bY/SraT9XnGJ0BgM/Bht325e9Y1/byB04DfAIe7sawDvlqrz5yR\nPpuKPV9GOqyXVHHcZwA7gRk57fI+R4q8Ywp9V9UYd86xFxj22YzL867qP3C9FLxojGfwIka+XQPj\n+RM8k8JjwKOuLMGz8W4EngUeDHzxAlzvxv840By41vnALlfOG6fxxxkWNh9wf5i73D9Wo6uf4vZ3\nueMfCJz/bXcvT1OhqJjUx8kAAACgSURBVKISxjwf2Oae+V3un6vmnzfwN8BTwBPA37sXXc09c+An\neH6lQTxN8oJKPl+g2T2D54DryAn2qPC4d+H5Mvz/zRtHe44UeMcU+q6qMe6c4y8wLGzG5XlbBgHD\nMAyj6pjPxjAMw6g6JmwMwzCMqmPCxjAMw6g6JmwMwzCMqmPCxjAMw6g6JmwMwzCMqmPCxjAMw6g6\nJmwMwzCMqvP/AyMKcb4PrcftAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1070cf588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train[:,1],Y_train,'k.',\n",
    "        X_train[:,1],predict_outcome(X_train, multiple_weights_0_penalty),'b.',\n",
    "        X_train[:,1],predict_outcome(X_train, multiple_weights_high_penalty),'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold cross validation to find l2-penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(k, l2_penalty, data, output,features=False,degree=False):\n",
    "    N = len(data)\n",
    "    RSS_list=[]\n",
    "    for i in range(k):\n",
    "        #get the fold splits for the current iteration\n",
    "        start = int(np.ceil((N*i)/k))\n",
    "        end = int(np.ceil((N*(i+1))/k-1))\n",
    "        training_data = data[0:start].append(data[end+1:N])\n",
    "        validation_data = data[start:end+1]\n",
    "        training_target = output[0:start].append(output[end+1:N])\n",
    "        validation_target= output[start:end+1]\n",
    "        \n",
    "        #training on training split\n",
    "        model = linear_model.Ridge(alpha=l2_penalty, normalize=True)\n",
    "        if (features):\n",
    "            model.fit(training_data[features], training_target)\n",
    "        else:\n",
    "            model.fit(training_data, training_target)\n",
    "        \n",
    "        #RSS on validation split\n",
    "        validation_data.loc[:,'price']=validation_target\n",
    "        if(degree):\n",
    "            features = [\"power_\"+str(i) for i in range(1,degree+1)] \n",
    "        X,Y=dataframe_prepare(dataframe=validation_data,features=features,target=['price'])\n",
    "        weights = np.concatenate((np.array([model.intercept_]), model.coef_),axis=0).reshape(-1,1) #merging intercept and coeffs\n",
    "        RSS = compute_RSS(X,Y,weights)\n",
    "        RSS_list.append(RSS)\n",
    "    return RSS_list,np.mean(RSS_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RSS(X,y,w):\n",
    "    RSS = np.matmul(np.transpose(y-predict_outcome(X,w)),y-predict_outcome(X,w))\n",
    "    return RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raiyanabdulbaten/Dropbox/ROC/handson-ml/my_codes/env/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/raiyanabdulbaten/Dropbox/ROC/handson-ml/my_codes/env/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best l2-penalty based on lowest RSS:0.003019951720402013\n",
      "Weights of final model: \n",
      "-99770.3868120372\n",
      "[243.73362872  66.54793933]\n",
      "Test set RSS with the best l2-penalty: [[2.7020516e+14]]\n"
     ]
    }
   ],
   "source": [
    "df_train_ridge_shuffled = shuffle(df_train_ridge)\n",
    "features = ['sqft_living', 'sqft_living15'] \n",
    "mean_RSS_list=[]\n",
    "\n",
    "#get best l2-penalty using 10-fold cross validation\n",
    "l2 = np.logspace(-9, 9, num=26)\n",
    "for l2_penalty in l2:\n",
    "    _ , mean_RSS = k_fold_cross_validation(k=10, l2_penalty=l2_penalty, data=df_train_ridge_shuffled, output=df_train_ridge_shuffled[\"price\"],features=['sqft_living', 'sqft_living15'],degree=False)\n",
    "    #print(mean_RSS)\n",
    "    mean_RSS_list.append(mean_RSS)\n",
    "\n",
    "val, idx = min((val, idx) for (idx, val) in enumerate(mean_RSS_list))\n",
    "print(\"Best l2-penalty based on lowest RSS:\"+str(l2[idx]))\n",
    "\n",
    "#training new model using best l2-penalty\n",
    "model = linear_model.Ridge(alpha=l2[idx], normalize=True)\n",
    "model.fit(df_train_ridge_shuffled[features], df_train_ridge_shuffled[\"price\"])\n",
    "print(\"Weights of final model: \")\n",
    "print(model.intercept_)\n",
    "print(model.coef_)\n",
    "\n",
    "#testing on test set\n",
    "\n",
    "X_test,Y_test=dataframe_prepare(dataframe=df_test_ridge,features=features,target=['price'])\n",
    "weights = np.concatenate((np.array([model.intercept_]), model.coef_),axis=0).reshape(-1,1)\n",
    "test_RSS = compute_RSS(X_test,Y_test,weights)\n",
    "print(\"Test set RSS with the best l2-penalty: \"+str(test_RSS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting the polynomial regression problem with k-fold CV\n",
    "Please refer to the polynomial regression code in the file 'Linear Regression Basics'. Here a maximum polynomial degree of 15 is used (which performed horribly without regularization). Using l2-penalty, the performance is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_shuffled = load_csv_data(\"data\",\"wk3_kc_house_train_valid_shuffled\",dtype_dict)\n",
    "test = load_csv_data(\"data\",\"wk3_kc_house_test_data\",dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_dataframe(feature, degree):\n",
    "    poly_dataframe = pd.DataFrame()\n",
    "    poly_dataframe[\"power_1\"] = feature\n",
    "    if degree > 1:\n",
    "        for power in range(2, degree+1):\n",
    "            name = 'power_' + str(power)\n",
    "            poly_dataframe[name] = feature.apply(lambda x: x**power)\n",
    "    return poly_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raiyanabdulbaten/Dropbox/ROC/handson-ml/my_codes/env/lib/python3.6/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/raiyanabdulbaten/Dropbox/ROC/handson-ml/my_codes/env/lib/python3.6/site-packages/pandas/core/indexing.py:621: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/Users/raiyanabdulbaten/Dropbox/ROC/handson-ml/my_codes/env/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best l2-penalty based on lowest RSS:0.08317637711026708\n",
      "Test set RSS with the best l2-penalty: [[1.37392658e+14]]\n"
     ]
    }
   ],
   "source": [
    "degree=15\n",
    "poly15_data = polynomial_dataframe(train_valid_shuffled['sqft_living'], degree)\n",
    "mean_RSS_list=[]\n",
    "\n",
    "#get best l2-penalty using 10-fold cross validation\n",
    "l2 = np.logspace(-9, 9, num=26)\n",
    "for l2_penalty in l2:\n",
    "    _ , mean_RSS = k_fold_cross_validation(k=10, l2_penalty=l2_penalty, data=poly15_data, output=train_valid_shuffled[\"price\"],features=False,degree=degree)\n",
    "    #print(mean_RSS)\n",
    "    mean_RSS_list.append(mean_RSS)\n",
    "\n",
    "val, idx = min((val, idx) for (idx, val) in enumerate(mean_RSS_list))\n",
    "print(\"Best l2-penalty based on lowest RSS:\"+str(l2[idx]))\n",
    "\n",
    "#training new model using best l2-penalty\n",
    "model = linear_model.Ridge(alpha=l2[idx], normalize=True)\n",
    "model.fit(poly15_data, train_valid_shuffled[\"price\"])\n",
    "\n",
    "#testing on test set\n",
    "poly15_test = polynomial_dataframe(test['sqft_living'], degree)\n",
    "poly15_test['price']=test['price']\n",
    "features = [\"power_\"+str(i) for i in range(1,degree+1)] \n",
    "X_test,Y_test=dataframe_prepare(dataframe=poly15_test,features=features,target=['price'])\n",
    "weights = np.concatenate((np.array([model.intercept_]), model.coef_),axis=0).reshape(-1,1)\n",
    "test_RSS = compute_RSS(X_test,Y_test,weights)\n",
    "print(\"Test set RSS with the best l2-penalty: \"+str(test_RSS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
